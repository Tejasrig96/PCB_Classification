{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PCB_Classification (PH023 & PH006).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XC0kXbevy3_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Input is a coloured 300x300 image \"\"\"\n",
        "#    (Balanced Data)\n",
        "\n",
        "from google.colab import drive\n",
        "from random import shuffle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Input, ZeroPadding2D, ZeroPadding1D, Dropout, BatchNormalization, GaussianNoise\n",
        "from tensorflow.keras import metrics\n",
        "from tensorflow.keras.metrics import AUC\n",
        "from tensorflow.keras import optimizers, regularizers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FWwheclzA0D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "# Loading data\n",
        "x_data = np.load('/content/drive/My Drive/xtrain.npy')\n",
        "y_data = np.load('/content/drive/My Drive/ytrain.npy')\n",
        "\n",
        "print(x_data.shape)\n",
        "print(y_data.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3p1BKr0fzDii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # Shuffling the data\n",
        "ind_list = [i for i in range(298)]\n",
        "shuffle(ind_list)\n",
        "\n",
        "\n",
        "# Shuffled data\n",
        "x_data_new = x_data[ind_list,:,:,:]\n",
        "y_data_new = y_data[ind_list,]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMkaoYw8zFYG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Architecture of the Network\n",
        "\n",
        "inputs = Input(shape=x_data_new.shape[1:])\n",
        "\n",
        "x = GaussianNoise(0.1)(inputs)\n",
        "\n",
        "x = Conv2D(filters=16, kernel_size=(3,3), strides=1, padding='valid', activation='relu', input_shape=x_data_new.shape[1:], kernel_regularizer=regularizers.l1_l2(0.01))(x)\n",
        "x = MaxPool2D(pool_size=(3,3), strides=1)(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "\n",
        "x = Conv2D(filters=9, kernel_size=(4,4), strides=1, padding='valid', activation='relu', input_shape=x_data_new.shape[1:], kernel_regularizer=regularizers.l1_l2(0.01))(x)\n",
        "x = MaxPool2D(pool_size=(4,4), strides=1)(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = Dropout(rate=0.50)(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "\n",
        "x = Dense(140, activation='relu', kernel_regularizer=regularizers.l1_l2(0.03))(x)\n",
        "\n",
        "x = Dropout(rate=0.50)(x)\n",
        "\n",
        "x = BatchNormalization()(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=predictions)\n",
        "\n",
        "opt = Adam(learning_rate=0.00001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[tf.keras.metrics.AUC()])\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "  rotation_range=10,\n",
        "  zoom_range=0.1,\n",
        "  width_shift_range=0.1,\n",
        "  height_shift_range=0.1,\n",
        "  validation_split = 0.2,\n",
        "  featurewise_std_normalization = True,\n",
        "  featurewise_center = True\n",
        ")\n",
        "# This also includes normalisation\n",
        "\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 35\n",
        "\n",
        "datagen.fit(x_data_new)\n",
        "\n",
        "# Separating training and validation data\n",
        "training_generator = datagen.flow(x_data_new, y_data_new, batch_size = batch_size,subset='training',seed=7) \n",
        "validation_generator = datagen.flow(x_data_new, y_data_new, batch_size= batch_size,subset='validation',seed=7)\n",
        "\n",
        "\n",
        "history = model.fit(training_generator, validation_data = validation_generator,\n",
        "                    steps_per_epoch = (len(x_data_new)*0.8) // batch_size, epochs = epochs, validation_steps=(len(x_data_new)*0.2)//batch_size,verbose=1, callbacks=None, shuffle = True)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zSzukVIzae0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plotting the confusion matrix\n",
        "true = validation_generator\n",
        "truelabel = true[0][1].tolist() + true[1][1].tolist()\n",
        "trueimg = true[0][0].tolist() + true[1][0].tolist()\n",
        "\n",
        "predict = model.predict(trueimg)\n",
        "\n",
        "predict = [np.round(x) for x in predict]\n",
        "cm=confusion_matrix(truelabel,predict)\n",
        "cm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r91nfPlxzf2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Visualizing\"\"\"\n",
        "\n",
        "#Training/Testing accuracy over epochs\n",
        "plt.plot(history.history['auc'], label='training accuracy')\n",
        "plt.plot(history.history['val_auc'], label='testing accuracy')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Loss Curve\n",
        "plt.plot(history.history['loss'], label='training loss')\n",
        "plt.plot(history.history['val_loss'], label='testing loss')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}